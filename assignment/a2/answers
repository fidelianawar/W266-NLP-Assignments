# Write your short answers in this file, replacing the placeholders as appropriate.
# This assignment consists of 1 parts for a total of 71 points.
# For numerical answers, copy and paste at least 5 significant figures.
# - Neural Network Text Classification (71 points)



###################################################################
###################################################################
## Neural Network Text Classification (71 points)
###################################################################
###################################################################


# ------------------------------------------------------------------
# | Section (2): Classification with various Word2Vec-based Models (2 points)  | 
# ------------------------------------------------------------------

# Question 2.a (/1): What is the percentage of positive examples in the training set (e.g. 72% is 0.72)?
neural_network_text_classification_2_2_a: 
- 0.49351

# Question 2.b (/1): What is the percentage of positive examples in the test set (e.g. 72% is 0.72)?
neural_network_text_classification_2_2_b: 
- 0.49688


# ------------------------------------------------------------------
# | Section (2.1): The Role of Shuffling of the Training Set (6 points)  | 
# ------------------------------------------------------------------

# Question 2.1.a (/3): Which number (in percent) is closest to the highest validation accuracy that you observed?
# (This question is multiple choice.  Delete all but the correct answer).
neural_network_text_classification_2_1_2_1_a: 
 - 50

# Question 2.1.b (/3): Which number (in percent) is closest to the highest validation accuracy that you observed for the shuffled run?
# (This question is multiple choice.  Delete all but the correct answer).
neural_network_text_classification_2_1_2_1_b: 
 - 75


# ------------------------------------------------------------------
# | Section (2.2): DAN vs Weighted Averaging Models using Attention (20 points)  | 
# ------------------------------------------------------------------

# Question 2.2.1.a (/2): Calculate the context vector for the following query and key/value vectors.
neural_network_text_classification_2_2_2_2_1_a: [0, 0.5, -1]

# Question 2.2.1.b (/2): What are the weights for the key/value vectors?
neural_network_text_classification_2_2_2_2_1_b: [0.5, 0.5]

# Question 2.2.2.a (/10): Which number (in percent) is closest to the highest validation accuracy that you observed for the wan training?
# (This question is multiple choice.  Delete all but the correct answer).
neural_network_text_classification_2_2_2_2_2_a: 
 - 78

# Question 2.2.2.b (/3): List the 5 most important words separated by commas. (Again, if a word appears twice, note it twice.)
neural_network_text_classification_2_2_2_2_2_b: [worst, terrible, pathetic, pathetic, disappointed]

# Question 2.2.2.c (/3): List the 5 least important words separated by commas. (Again, if a word appears twice, note it twice.)
neural_network_text_classification_2_2_2_2_2_c: [the, or, their, their, their]


# ------------------------------------------------------------------
# | Section (2.3): Approaches for Training of Embeddings (9 points)  | 
# ------------------------------------------------------------------

# Question 2.3.a (/3): Which number (in percent) is closest to the highest validation accuracy that you observed for the static model?
# (This question is multiple choice.  Delete all but the correct answer).
neural_network_text_classification_2_3_2_3_a: 
 - 76

# Question 2.3.b (/3): Which number (in percent) is closest to the highest validation accuracy that you observed for the model where you initialized with word2vec vectors but allow them to retrain?
# (This question is multiple choice.  Delete all but the correct answer).
neural_network_text_classification_2_3_2_3_b: 
 - 81

# Question 2.3.c (/3): Which number (in percent) is closest to the highest validation accuracy that you observed for the model where you initialized randomly and then trained?
# (This question is multiple choice.  Delete all but the correct answer).
neural_network_text_classification_2_3_2_3_c: 
 - 80


# ------------------------------------------------------------------
# | Section (3): Classification with BERT (34 points)  | 
# ------------------------------------------------------------------

# Question 3.1.a (/1): Why do the attention_masks have 4 and 1 zeros, respectively?
# (This question is multiple choice.  Delete all but the correct answer).
neural_network_text_classification_3_3_1_a: 
 - For the first example 5 positions are padded while for the second one it is only one.

# Question 3.1.b (/1): How many outputs are there?
neural_network_text_classification_3_3_1_b: 
- 2

# Question 3.1.c (/1): Which output do we need to use to get token-level embeddings?
# (This question is multiple choice.  Delete all but the correct answer).
neural_network_text_classification_3_3_1_c: 
 - the first

# Question 3.1.d (/2): Which token number corresponds to 'bank' in the first sentence?
neural_network_text_classification_3_3_1_d: 
- 2

# Question 3.1.e (/2): Which token number corresponds to 'bank' in the second sentence?
neural_network_text_classification_3_3_1_e: 
- 4

# Question 3.1.f (/3): What is the cosine similarity between the BERT outputs for the two occurences of 'bank' in the two sentences?
neural_network_text_classification_3_3_1_f: 
- 0.74783

# Question 3.1.g (/3): How does this relate to the cosine similarity of 'this' (sentence 1) and 'the' (sentence 2). Compute the cosine similarity.
neural_network_text_classification_3_3_1_g: 
- 0.81103

# Question 3.2.a (/7): Which number (in percent) is closest to the highest validation accuracy that you observed for the [CLS]-classification model?
# (This question is multiple choice.  Delete all but the correct answer).
neural_network_text_classification_3_3_2_a: 
 - 82

# Question 3.3.a (/7): Which number (in percent) is closest to the highest validation accuracy that you observed for the BERT-averaging-classification model?
# (This question is multiple choice.  Delete all but the correct answer).
neural_network_text_classification_3_3_3_a: 
 - 84

# Question 3.4.a (/7): Which number (in percent) is closest to the highest validation accuracy that you observed for the BERT-CNN-classification model?
# (This question is multiple choice.  Delete all but the correct answer).
neural_network_text_classification_3_3_4_a: 
 - 84
